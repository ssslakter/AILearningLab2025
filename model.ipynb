{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "file_path = 'dataset_comments.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path, names=['UserSenderId', 'SubmitDate', 'MessageText'])\n",
    "\n",
    "def clean_html(content):\n",
    "    if isinstance(content, str):\n",
    "        # Use BeautifulSoup to remove HTML tags\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        return soup.get_text()\n",
    "    return content  # Return as is if not a string\n",
    "\n",
    "df['Text'] = df['MessageText'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserSenderId</th>\n",
       "      <th>SubmitDate</th>\n",
       "      <th>MessageText</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14771</td>\n",
       "      <td>2023-05-16 19:27:21.773</td>\n",
       "      <td>&lt;p class=\"st0\"&gt;–í –æ–±—â–µ–º podman ...</td>\n",
       "      <td>–í –æ–±—â–µ–º podman - —ç—Ç–æ –Ω–µ –Ω–∞—à –º–µ—Ç–æ–¥. –ù–∞ –Ω–µ–º —Ä–∞–±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8194</td>\n",
       "      <td>2023-05-16 16:56:35.380</td>\n",
       "      <td>&lt;p class=\"st0\"&gt;–ê –∑–∞—á–µ–º –≤–≤–æ–¥ –ò–ù–ù? –ï—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç ...</td>\n",
       "      <td>–ê –∑–∞—á–µ–º –≤–≤–æ–¥ –ò–ù–ù? –ï—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç —É –∫–æ–º–ø–∞–Ω–∏–∏, —Ç–æ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18355</td>\n",
       "      <td>2023-05-16 15:08:17.097</td>\n",
       "      <td>—Å–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –ø–æ–∂–∞–ª—É–π—Å—Ç–∞</td>\n",
       "      <td>—Å–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –ø–æ–∂–∞–ª—É–π—Å—Ç–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18551</td>\n",
       "      <td>2023-05-16 09:33:51.050</td>\n",
       "      <td>—Ç–æ–ª—Å—Ç–æ–≤–∫–∞ —Ö–æ—Ä–æ—à–∞—è, –Ω–æ –Ω–∞—á–µ—Å –ª–µ–∑–µ—Ç —Å–∏–ª—å–Ω–æ.  –Ω–∞–¥...</td>\n",
       "      <td>—Ç–æ–ª—Å—Ç–æ–≤–∫–∞ —Ö–æ—Ä–æ—à–∞—è, –Ω–æ –Ω–∞—á–µ—Å –ª–µ–∑–µ—Ç —Å–∏–ª—å–Ω–æ.  –Ω–∞–¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14634</td>\n",
       "      <td>2023-05-15 14:21:37.207</td>\n",
       "      <td>&lt;p class=\"st0\"&gt;–ó–¥–æ—Ä–æ–≤–æ! –ù–∞—â—É–ø–∞–ª–∏ –∏–¥–µ–∞–ª—å–Ω—ã–π —Ñ–æ—Ä...</td>\n",
       "      <td>–ó–¥–æ—Ä–æ–≤–æ! –ù–∞—â—É–ø–∞–ª–∏ –∏–¥–µ–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç üòéüëçüëç–ò–∑ –ø—Ä–µ–¥–ª...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserSenderId              SubmitDate  \\\n",
       "0         14771 2023-05-16 19:27:21.773   \n",
       "1          8194 2023-05-16 16:56:35.380   \n",
       "2         18355 2023-05-16 15:08:17.097   \n",
       "3         18551 2023-05-16 09:33:51.050   \n",
       "4         14634 2023-05-15 14:21:37.207   \n",
       "\n",
       "                                         MessageText  \\\n",
       "0                  <p class=\"st0\">–í –æ–±—â–µ–º podman ...   \n",
       "1  <p class=\"st0\">–ê –∑–∞—á–µ–º –≤–≤–æ–¥ –ò–ù–ù? –ï—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç ...   \n",
       "2               —Å–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –ø–æ–∂–∞–ª—É–π—Å—Ç–∞   \n",
       "3  —Ç–æ–ª—Å—Ç–æ–≤–∫–∞ —Ö–æ—Ä–æ—à–∞—è, –Ω–æ –Ω–∞—á–µ—Å –ª–µ–∑–µ—Ç —Å–∏–ª—å–Ω–æ.  –Ω–∞–¥...   \n",
       "4  <p class=\"st0\">–ó–¥–æ—Ä–æ–≤–æ! –ù–∞—â—É–ø–∞–ª–∏ –∏–¥–µ–∞–ª—å–Ω—ã–π —Ñ–æ—Ä...   \n",
       "\n",
       "                                                Text  \n",
       "0   –í –æ–±—â–µ–º podman - —ç—Ç–æ –Ω–µ –Ω–∞—à –º–µ—Ç–æ–¥. –ù–∞ –Ω–µ–º —Ä–∞–±...  \n",
       "1  –ê –∑–∞—á–µ–º –≤–≤–æ–¥ –ò–ù–ù? –ï—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç —É –∫–æ–º–ø–∞–Ω–∏–∏, —Ç–æ ...  \n",
       "2               —Å–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –ø–æ–∂–∞–ª—É–π—Å—Ç–∞  \n",
       "3  —Ç–æ–ª—Å—Ç–æ–≤–∫–∞ —Ö–æ—Ä–æ—à–∞—è, –Ω–æ –Ω–∞—á–µ—Å –ª–µ–∑–µ—Ç —Å–∏–ª—å–Ω–æ.  –Ω–∞–¥...  \n",
       "4  –ó–¥–æ—Ä–æ–≤–æ! –ù–∞—â—É–ø–∞–ª–∏ –∏–¥–µ–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç üòéüëçüëç–ò–∑ –ø—Ä–µ–¥–ª...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"cointegrated/rubert-tiny-sentiment-balanced\", batch_size=8, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pipe(df['Text'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [el['label'] for el in res]\n",
    "df['score'] = [el['score'] for el in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('a.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('onnx/tokenizer_config.json',\n",
       " 'onnx/special_tokens_map.json',\n",
       " 'onnx/vocab.txt',\n",
       " 'onnx/added_tokens.json',\n",
       " 'onnx/tokenizer.json')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"cointegrated/rubert-tiny-sentiment-balanced\"\n",
    "save_directory = \"onnx/\"\n",
    "\n",
    "# Load a model from transformers and export it to ONNX\n",
    "ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Save the onnx model and tokenizer\n",
    "ort_model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from optimum.pipelines import pipeline\n",
    "classifier = pipeline(task=\"text-classification\", accelerator=\"ort\", model = \"cointegrated/rubert-tiny-sentiment-balanced\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.706735372543335}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(df['Text'][3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
